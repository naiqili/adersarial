{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim0 = 28\n",
    "dim = dim0*dim0 # dim of the original img\n",
    "kernel_size = 6\n",
    "stride = 3\n",
    "q_dim = 8192 # dim of the quantized img\n",
    "k_fs = 5\n",
    "suffix = '_reg_divide'\n",
    "\n",
    "_device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = 'D:\\Lab\\dataset'\n",
    "\n",
    "total_train_dataset = datasets.MNIST(dataroot, train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ]))\n",
    "\n",
    "total_train_size = len(total_train_dataset)\n",
    "split_ratio = 0.8\n",
    "train_size = int(split_ratio * total_train_size)\n",
    "valid_size = total_train_size - train_size\n",
    "\n",
    "train_dataset, valid_dataset = random_split(total_train_dataset,[train_size, valid_size])\n",
    "print('n: {}'.format(len(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use kmeans to quantize dataset\n",
    "b_size = 48000\n",
    "kmeans_epochs = 10000\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=b_size, shuffle=True)\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=q_dim, batch_size=b_size)\n",
    "_loss = 1e10\n",
    "_cts = np.zeros((q_dim, 6*6))\n",
    "_patience = max_patience = 2\n",
    "print(kmeans)\n",
    "\n",
    "for _epoch in range(kmeans_epochs):\n",
    "    it = iter(train_loader)\n",
    "    x = np.random.randint(0, 28-kernel_size+1)\n",
    "    y = np.random.randint(0, 28-kernel_size+1)\n",
    "    img, label = it.next()\n",
    "    while True:\n",
    "        try:\n",
    "            img = img[:, 0, x:x+6, y:y+6]\n",
    "            img = img.reshape(img.shape[0], -1)\n",
    "            assert(img.shape[1] == kernel_size**2)\n",
    "            kmeans.partial_fit(img)\n",
    "        except:\n",
    "            break\n",
    "    _new_loss = np.sum(kmeans.cluster_centers_ - _cts)\n",
    "    print('Epoch {} finishes. Loss: {}'.format(_epoch, _new_loss))\n",
    "    _cts = kmeans.cluster_centers_\n",
    "    if _new_loss < _loss:\n",
    "        _loss = _new_loss\n",
    "        _patience = max_patience\n",
    "    else:\n",
    "        _patience -= 1\n",
    "        if _patience == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts = kmeans.cluster_centers_\n",
    "cts_ts = torch.from_numpy(cts)\n",
    "def imshow(img):\n",
    "    plt.figure(figsize=(30,30))\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(cts_ts.view((cts_ts.shape[0], 1, 6, 6))[:128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trans(object):\n",
    "    def __init__(self, kmeans=kmeans):\n",
    "        self.kmeans = kmeans\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        res = np.zeros((8, 8))\n",
    "        for x in range(0, 8):\n",
    "            for y in range(0, 8):\n",
    "                res[x, y] = self.kmeans.predict(img[3*x:3*x+6, 3*y:3*y+6].reshape(1, -1))[0]\n",
    "        return torch.from_numpy(res.reshape(-1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.dataset.transform = Trans()\n",
    "valid_dataset.dataset.transform = Trans()\n",
    "test_dataset = datasets.MNIST(dataroot, train=False, download=True,\n",
    "                   transform=Trans())\n",
    "test_size = len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=b_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=b_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=b_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = iter(train_loader).next()\n",
    "\n",
    "print(img)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "n_epochs = 500\n",
    "lr = 0.0001\n",
    "valid_step = 100\n",
    "patience = max_patience = 20\n",
    "best_loss = 100000\n",
    "best_acc = 0\n",
    "model_file = './models/model_info' + suffix + '.md'\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(64, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = F.dropout(x, training=self.training, p=0.8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training, p=0.2)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)    \n",
    "\n",
    "def test_validate(model, device, test_loader, test_valid='Test'):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\n{} set: Average loss: {:.6f}, Accuracy: {}/{} ({:.6f}%)\\n'.format(\n",
    "        test_valid, test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss, test_acc\n",
    "    \n",
    "def train(model, device, train_loader, valid_loader, optimizer, epoch):\n",
    "    global best_loss, best_acc, patience\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #print(data[0].numpy()[:28*28])\n",
    "        #print(target[0])\n",
    "        model.train()\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "        if (batch_idx+1) % valid_step == 0:\n",
    "            print('Start Validating...')\n",
    "            valid_loss, valid_acc = test_validate(model, device, valid_loader, 'Valid')\n",
    "            # Very strange. Acc. improve, but loss increase.\n",
    "            # if valid_loss < best_loss:\n",
    "            #    best_loss = valid_loss\n",
    "            if valid_acc > best_acc:\n",
    "                best_acc = valid_acc\n",
    "                patience = max_patience\n",
    "                #print('Bese valid loss: {}'.format(best_loss))\n",
    "                print('Improved! Reset patience.')\n",
    "                print('Saving model...')\n",
    "                torch.save(model, model_file)\n",
    "            else:\n",
    "                patience -= 1\n",
    "                print('Not improved... Patience: {}'.format(patience))\n",
    "                if patience == 0:\n",
    "                    print('Out of patience. Stop training.')\n",
    "                    return\n",
    "\n",
    "def main():        \n",
    "    dataroot = 'D:\\Lab\\dataset'\n",
    "    \n",
    "    print(len(train_loader.dataset))\n",
    "    device = torch.device(_device)\n",
    "    \n",
    "    model = Net().to(device)\n",
    "    print(model)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train(model, device, train_loader, valid_loader, optimizer, epoch)\n",
    "        if patience == 0:\n",
    "            break\n",
    "                \n",
    "    print('Start testing...')\n",
    "    model = torch.load(model_file)\n",
    "    test_validate(model, device, test_loader)\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps a pixel to quantized index\n",
    "def q_map(x, threshold=0.4):\n",
    "    if x < threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "# given a data matrix, returns the mask\n",
    "def q_mask(X):\n",
    "    mask = np.zeros((X.shape[0], X.shape[1]*q_dim), dtype=np.float)\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            mask[i, j*q_dim+q_map(X[i,j])] = 1\n",
    "    norm_p = np.sum(mask, axis=0) / X.shape[0]\n",
    "    return mask, norm_p\n",
    "\n",
    "# X: data matrix\n",
    "# feature extracting func\n",
    "# vanilla implementation too slow. use batch.\n",
    "def ACE_step(X, f, lr, batch_size, mask, norm_p):\n",
    "    # E[sum f(X_j)|X_i], res is f.dim = data.dim*q_dim\n",
    "    def expect_cond(X, f, idx):\n",
    "        f_mask = np.tile(f, (len(idx), 1)) * mask[idx, :]\n",
    "        sum_per_row = np.sum(f_mask, axis=1)\n",
    "        sum_per_col = np.sum(f_mask, axis=0)\n",
    "        res = np.zeros_like(f)\n",
    "        for j in range(f.shape[0]):\n",
    "            # if j % 500 == 0: print('expect_cond: {}-th column'.format(j))\n",
    "            b = (mask[idx, j] == 1)\n",
    "            if np.sum(b) > 0:\n",
    "                res[j] = (np.sum(b * sum_per_row) - np.sum(sum_per_col[j])) / np.sum(b)\n",
    "        return res\n",
    "    \n",
    "    # sqrt(E[sum f(X_i)^2])\n",
    "    def expect_var(X, f):\n",
    "        # sum_cov = np.sum(np.sum((np.tile(f, (X.shape[0], 1))*mask)**2))\n",
    "        # e_cov = sum_cov / X.shape[0]\n",
    "        # res = np.sqrt(e_cov)\n",
    "        \n",
    "        res = np.sqrt(np.sum((f**2) * norm_p))\n",
    "        return res\n",
    "    \n",
    "    batch_idx = np.random.choice(X.shape[0], batch_size, False)\n",
    "    e_cond = expect_cond(X, f, batch_idx)\n",
    "    new_f = f + lr*e_cond\n",
    "    cov = expect_var(X, new_f)\n",
    "    \n",
    "    new_f = new_f / cov\n",
    "    return new_f\n",
    "\n",
    "def init_f(dim=28*28, q_dim=2):\n",
    "    res_dim = dim * q_dim\n",
    "    res = np.random.rand(res_dim)\n",
    "    for j in range(dim):\n",
    "        res[j*q_dim : (j+1)*q_dim] -= np.sum(res[j*q_dim : (j+1)*q_dim])/2\n",
    "    return res\n",
    "\n",
    "def ACE_f(X, mask, norm_p, lr, batch_size, dim=28*28, q_dim=2, epsilon=0.01, max_step=500):\n",
    "    f_1 = init_f(dim, q_dim)\n",
    "    for _step in range(max_step):\n",
    "        f_2 = ACE_step(X, f_1, lr, batch_size, mask, norm_p)\n",
    "        delta = np.sum((f_1 - f_2)**2)\n",
    "        f_1 = f_2\n",
    "        print('Step {}: delta after ACE_step: {}'.format(_step, delta))\n",
    "        if delta < epsilon:\n",
    "            break\n",
    "    return f_1\n",
    "\n",
    "def norm_dot(f1, f2, norm_p):\n",
    "    res = np.sum(f1 * f2 * norm_p)\n",
    "    return res\n",
    "\n",
    "def ACE_fs(X, k, mask, norm_p, lr=0.8, batch_size=512, dim=28*28, q_dim=2, epsilon=0.01, max_step=500):\n",
    "    res = []\n",
    "    for i in range(k):\n",
    "        print('Building the {}-th feature function...'.format(i))\n",
    "        f_i = ACE_f(X, mask, norm_p, lr, batch_size, dim, q_dim, epsilon, max_step)\n",
    "        f_tmp = np.zeros_like(f_i)\n",
    "        for f_m in res:\n",
    "            f_tmp = f_tmp + norm_dot(f_i, f_m, norm_p)*f_m\n",
    "        f_i -= f_tmp\n",
    "        res.append(f_i)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the training MNIST as a big matrix\n",
    "\n",
    "X: n x (28*28)\n",
    "mask: n x (28*28*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((train_size, dim))\n",
    "for idx, (img, _) in enumerate(train_dataset):\n",
    "    X[idx, :] = img.numpy().transpose(1, 2, 0).flatten()\n",
    "    if idx%5000 == 0: print(idx)\n",
    "mask, norm_p = q_mask(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(mask.shape)\n",
    "print(mask[0][700:800])\n",
    "print(norm_p.shape)\n",
    "print(norm_p[700:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the feature extracting func. f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "feature_path = './models/feats' + suffix\n",
    "\n",
    "if False:\n",
    "    fs = ACE_fs(X, k_fs, mask, norm_p, 1, train_size, epsilon=0.0000000001, max_step=10)\n",
    "    with open(feature_path, 'wb') as fp:\n",
    "        pickle.dump(fs, fp)\n",
    "else:\n",
    "    with open(feature_path, 'rb') as fp:\n",
    "        fs = pickle.load(fp)\n",
    "print(len(fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfoTrans(object):\n",
    "    def __init__(self, map_func, q_dim, fs):\n",
    "        self.map_func = map_func\n",
    "        self.fs = fs\n",
    "        self.k_fs = len(fs)\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        img = img.numpy().transpose(1, 2, 0).flatten()\n",
    "        dim = len(img)\n",
    "        \n",
    "        # returns features\n",
    "        feats = np.zeros(self.k_fs*len(img))\n",
    "        for idx, pixel in enumerate(img):\n",
    "            for k in range(self.k_fs):\n",
    "                feats[k*dim+idx] = self.fs[k][idx*q_dim+self.map_func(pixel)]\n",
    "        feats = feats\n",
    "        \n",
    "        return feats   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_file = './models/processed_train' + suffix + '.npz'\n",
    "processed_valid_file = './models/processed_valid' + suffix + '.npz'\n",
    "processed_test_file = './models/processed_test' + suffix + '.npz'\n",
    "train_max_min_file = './models/train_max_min' + suffix + '.npz'\n",
    "\n",
    "if False:\n",
    "    processed_train = np.zeros((train_size, k_fs*dim))\n",
    "    processed_label = np.zeros((train_size, 1))\n",
    "    for idx, (img, label) in enumerate(train_dataset):\n",
    "        processed_train[idx, :] = InfoTrans(q_map, q_dim, fs)(img)\n",
    "        processed_label[idx, 0] = label\n",
    "        if idx%1000==0: print(idx)\n",
    "            \n",
    "    train_min, train_max = np.zeros(k_fs), np.zeros(k_fs)\n",
    "    for k in range(k_fs):\n",
    "        train_max[k] = np.max(processed_train[:, k*dim:(k+1)*dim])\n",
    "        train_min[k] = np.min(processed_train[:, k*dim:(k+1)*dim])\n",
    "        \n",
    "    print(train_max)\n",
    "    print(train_min)\n",
    "    \n",
    "    with open(train_max_min_file, 'wb') as fp:\n",
    "        np.savez(fp, train_max=train_max, train_min=train_min)\n",
    "    \n",
    "    for k in range(k_fs):\n",
    "        processed_train[:, k*dim:(k+1)*dim] = (processed_train[:, k*dim:(k+1)*dim] - train_min[k]) / (train_max[k] - train_min[k]) * 2 - 1\n",
    "\n",
    "    with open(processed_train_file, 'wb') as fp:\n",
    "        #torch.save(processed_train, fp)\n",
    "        np.savez(fp, img=processed_train, label=processed_label)\n",
    "\n",
    "    processed_valid = np.zeros((valid_size, k_fs*dim))\n",
    "    processed_label = np.zeros((valid_size, 1))\n",
    "    for idx, (img, label) in enumerate(valid_dataset):\n",
    "        processed_valid[idx, :] = InfoTrans(q_map, q_dim, fs)(img)\n",
    "        processed_label[idx, 0] = label\n",
    "        if idx%1000==0: print(idx)\n",
    "        \n",
    "    for k in range(k_fs):\n",
    "        processed_valid[:, k*dim:(k+1)*dim] = (processed_valid[:, k*dim:(k+1)*dim] - train_min[k]) / (train_max[k] - train_min[k]) * 2 - 1\n",
    "        \n",
    "    with open(processed_valid_file, 'wb') as fp:\n",
    "        #torch.save(processed_valid, fp)\n",
    "        np.savez(fp, img=processed_valid, label=processed_label)\n",
    "\n",
    "    processed_test = np.zeros((test_size, k_fs*dim))\n",
    "    processed_label = np.zeros((test_size, 1))\n",
    "    for idx, (img, label) in enumerate(test_dataset):\n",
    "        processed_test[idx, :] = InfoTrans(q_map, q_dim, fs)(img)\n",
    "        processed_label[idx, 0] = label\n",
    "        if idx%1000==0: print(idx)            \n",
    "        \n",
    "    for k in range(k_fs):\n",
    "        processed_test[:, k*dim:(k+1)*dim] = (processed_test[:, k*dim:(k+1)*dim] - train_min[k]) / (train_max[k] - train_min[k]) * 2 - 1\n",
    "\n",
    "    with open(processed_test_file, 'wb') as fp:\n",
    "        #torch.save(processed_test, fp)\n",
    "        np.savez(fp, img=processed_test, label=processed_label)\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfoMNIST(torch.utils.data.Dataset):\n",
    "    def __init__(self, train=True, transform=None, target_transform=None, \n",
    "                 processed_train_file = processed_train_file,\n",
    "                 processed_valid_file = processed_valid_file, \n",
    "                 processed_test_file = processed_test_file):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if self.train=='train':\n",
    "            filename = processed_train_file\n",
    "        elif self.train=='valid':\n",
    "            filename = processed_valid_file\n",
    "        else:\n",
    "            filename = processed_test_file\n",
    "        with open(filename, 'rb') as fp:\n",
    "            npzfile = np.load(fp)\n",
    "            self.length = npzfile['label'].shape[0]\n",
    "            self.img = torch.from_numpy(npzfile['img']).float()\n",
    "            self.label = torch.from_numpy(npzfile['label'].flatten()).long()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.img[index], self.label[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_var_file = './models/mean_var'\n",
    "\n",
    "if True:\n",
    "    b_size = 20000\n",
    "\n",
    "    train_loader_vis = torch.utils.data.DataLoader(\n",
    "        InfoMNIST('train'),\n",
    "        batch_size=b_size, shuffle=True)\n",
    "    '''\n",
    "    train_mean = torch.zeros((1, k_fs*dim))\n",
    "    train_var = torch.zeros((1, k_fs*dim))\n",
    "    for img, label in train_loader_vis:\n",
    "        train_mean += torch.sum(img, 0, keepdim=True)\n",
    "    train_mean /= train_size\n",
    "\n",
    "    for img, label in train_loader_vis:\n",
    "        train_var += torch.sum((img - train_mean)**2, 0, keepdim=True)\n",
    "    train_var = torch.sqrt(train_var) / train_size\n",
    "    \n",
    "    train_mean = train_mean.numpy()\n",
    "    train_var = train_var.numpy()\n",
    "    '''\n",
    "    train_mean, train_var, train_min, train_max = np.zeros(k_fs), np.zeros(k_fs), np.zeros(k_fs), np.zeros(k_fs)\n",
    "    for img, label in train_loader_vis:\n",
    "        for k in range(k_fs):\n",
    "            train_mean[k] = np.mean(img.numpy()[:, k*dim:(k+1)*dim])        \n",
    "            train_var[k] = np.var(img.numpy()[:, k*dim:(k+1)*dim])\n",
    "            train_max[k] = np.max(img.numpy()[:, k*dim:(k+1)*dim])\n",
    "            train_min[k] = np.min(img.numpy()[:, k*dim:(k+1)*dim])\n",
    "        break\n",
    "    \n",
    "    with open(mean_var_file, 'wb') as fp:\n",
    "        np.savez(fp, mean=train_mean, var=train_var)\n",
    "else:\n",
    "    with open(mean_var_file, 'rb') as fp:\n",
    "        npzfile = np.load(fp)\n",
    "        train_mean, train_var = npzfile['mean'], npzfile['var']\n",
    "\n",
    "print(train_mean)\n",
    "print(train_var) \n",
    "print(train_max)\n",
    "print(train_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class NormalTrans(object):\n",
    "    def __init__(self, mean, var, _max, _min):\n",
    "        self.mean = mean\n",
    "        self.var = var\n",
    "        self._max = _max\n",
    "        self._min = _min\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        res = img\n",
    "        for k in range(k_fs):\n",
    "            res[k*dim:(k+1)*dim] = (img[k*dim:(k+1)*dim] - self._min[k]) / (self._max[k] - self._min[k]) * 2 - 1#/ self.var        \n",
    "        return res   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(test_loader)\n",
    "test_img, test_label = it.next()\n",
    "print(test_img.shape)\n",
    "for i in range(k_fs):\n",
    "    print(torch.mean(test_img[0][i*28*28:(i+1)*28*28], 0))\n",
    "print(test_img[0][:])\n",
    "print(test_label.shape)\n",
    "for i in range(5):\n",
    "    test_img, test_label = it.next()\n",
    "    plt.hist(test_img[0][28*28:2*28*28])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize the 1st feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(npimg):\n",
    "    npimg = npimg * 0.5 + 0.5\n",
    "    npimg = npimg.reshape((28,28))\n",
    "    plt.imshow(npimg, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1):\n",
    "    for j in range(8):\n",
    "        print(test_img[j])\n",
    "        imshow(test_img[j].numpy()[k*28*28:(k+1)*28*28])\n",
    "        print(test_label[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fs[0].shape)\n",
    "print(fs[0][:50])\n",
    "plt.hist(fs[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
